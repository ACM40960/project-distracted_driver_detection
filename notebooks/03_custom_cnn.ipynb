{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e59be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Dense, Dropout, \n",
    "                                     Flatten, BatchNormalization)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "181eefe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8442 validated image filenames belonging to 3 classes.\n",
      "Found 2814 validated image filenames belonging to 3 classes.\n",
      "Found 2814 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image dimensions\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Define image augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# No augmentation for validation and test data — only rescaling\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Path to CSV files\n",
    "train_csv = '../split_data/training_data.csv'\n",
    "val_csv = '../split_data/validation_data.csv'\n",
    "test_csv = '../split_data/testing_data.csv'\n",
    "\n",
    "# Path to image folders\n",
    "train_dir = '../split_data/training'\n",
    "val_dir = '../split_data/validation'\n",
    "test_dir = '../split_data/testing'\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv(train_csv)\n",
    "val_df = pd.read_csv(val_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "# Create data generators using flow_from_dataframe\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=train_dir,\n",
    "    x_col='img_id',\n",
    "    y_col='class_id',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=val_dir,\n",
    "    x_col='img_id',\n",
    "    y_col='class_id',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_dir,\n",
    "    x_col='img_id',\n",
    "    y_col='class_id',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "124e4ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed class weights: {'drinking': np.float64(2.0172043010752687), 'safe_driving': np.float64(1.884795713328868), 'using_phone': np.float64(0.5066618653222903)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "class_labels = train_df['class_id']\n",
    "classes = np.unique(class_labels)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=class_labels\n",
    ")\n",
    "class_weights_dict = dict(zip(classes, class_weights))\n",
    "print(\"Computed class weights:\", class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504d876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,184</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m12,845,184\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,939,715</span> (49.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,939,715\u001b[0m (49.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,939,267</span> (49.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,939,267\u001b[0m (49.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def build_stable_custom_cnn(input_shape=(224, 224, 3), num_classes=3):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Block 1\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(0.0001), input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(0.0001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(0.0001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # FC Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "    model.add(Dropout(0.4))  # Only one dropout here\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and compile\n",
    "model = build_stable_custom_cnn()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "544241dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping & learning rate decay\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Save the best model\n",
    "checkpoint = ModelCheckpoint(\"best_stable_model.h5\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ada47530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963ms/step - accuracy: 0.6126 - loss: 2.9574 - precision: 0.5486 - recall: 0.1745\n",
      "Epoch 1: val_loss improved from inf to 6.86923, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 1s/step - accuracy: 0.6127 - loss: 2.9519 - precision: 0.5489 - recall: 0.1744 - val_accuracy: 0.5821 - val_loss: 6.8692 - val_precision: 0.5821 - val_recall: 0.5821 - learning_rate: 5.0000e-04\n",
      "Epoch 2/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952ms/step - accuracy: 0.6615 - loss: 0.9778 - precision: 0.6776 - recall: 0.3707\n",
      "Epoch 2: val_loss improved from 6.86923 to 0.93269, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - accuracy: 0.6614 - loss: 0.9778 - precision: 0.6777 - recall: 0.3706 - val_accuracy: 0.6521 - val_loss: 0.9327 - val_precision: 0.7831 - val_recall: 0.4851 - learning_rate: 5.0000e-04\n",
      "Epoch 3/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969ms/step - accuracy: 0.6518 - loss: 0.9402 - precision: 0.7169 - recall: 0.3487\n",
      "Epoch 3: val_loss improved from 0.93269 to 0.80249, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 1s/step - accuracy: 0.6518 - loss: 0.9402 - precision: 0.7169 - recall: 0.3487 - val_accuracy: 0.6578 - val_loss: 0.8025 - val_precision: 0.7357 - val_recall: 0.6439 - learning_rate: 5.0000e-04\n",
      "Epoch 4/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6510 - loss: 0.9128 - precision: 0.7625 - recall: 0.3193\n",
      "Epoch 4: val_loss did not improve from 0.80249\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.6511 - loss: 0.9128 - precision: 0.7626 - recall: 0.3194 - val_accuracy: 0.6578 - val_loss: 0.9100 - val_precision: 0.6633 - val_recall: 0.6567 - learning_rate: 5.0000e-04\n",
      "Epoch 5/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6515 - loss: 0.9055 - precision: 0.7642 - recall: 0.3120\n",
      "Epoch 5: val_loss improved from 0.80249 to 0.78333, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 1s/step - accuracy: 0.6515 - loss: 0.9055 - precision: 0.7643 - recall: 0.3120 - val_accuracy: 0.6578 - val_loss: 0.7833 - val_precision: 0.8316 - val_recall: 0.5633 - learning_rate: 5.0000e-04\n",
      "Epoch 6/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6591 - loss: 0.8746 - precision: 0.8124 - recall: 0.3129\n",
      "Epoch 6: val_loss improved from 0.78333 to 0.73179, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 1s/step - accuracy: 0.6591 - loss: 0.8745 - precision: 0.8122 - recall: 0.3131 - val_accuracy: 0.6578 - val_loss: 0.7318 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 5.0000e-04\n",
      "Epoch 7/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6594 - loss: 0.8502 - precision: 0.6594 - recall: 0.6594\n",
      "Epoch 7: val_loss did not improve from 0.73179\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 1s/step - accuracy: 0.6594 - loss: 0.8502 - precision: 0.6594 - recall: 0.6594 - val_accuracy: 0.6578 - val_loss: 0.7578 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6666 - loss: 0.8290 - precision: 0.6666 - recall: 0.6666\n",
      "Epoch 8: val_loss did not improve from 0.73179\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 1s/step - accuracy: 0.6666 - loss: 0.8290 - precision: 0.6666 - recall: 0.6666 - val_accuracy: 0.6578 - val_loss: 0.9209 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 5.0000e-04\n",
      "Epoch 9/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938ms/step - accuracy: 0.6524 - loss: 0.8443 - precision: 0.6524 - recall: 0.6524\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.73179\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 996ms/step - accuracy: 0.6524 - loss: 0.8443 - precision: 0.6524 - recall: 0.6524 - val_accuracy: 0.6578 - val_loss: 0.8477 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917ms/step - accuracy: 0.6521 - loss: 0.8139 - precision: 0.6521 - recall: 0.6521\n",
      "Epoch 10: val_loss improved from 0.73179 to 0.69250, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 976ms/step - accuracy: 0.6521 - loss: 0.8138 - precision: 0.6521 - recall: 0.6521 - val_accuracy: 0.6578 - val_loss: 0.6925 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 1.5000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918ms/step - accuracy: 0.6623 - loss: 0.7862 - precision: 0.6623 - recall: 0.6623\n",
      "Epoch 11: val_loss improved from 0.69250 to 0.67940, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 976ms/step - accuracy: 0.6623 - loss: 0.7862 - precision: 0.6623 - recall: 0.6623 - val_accuracy: 0.6578 - val_loss: 0.6794 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 1.5000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913ms/step - accuracy: 0.6639 - loss: 0.7707 - precision: 0.6639 - recall: 0.6639\n",
      "Epoch 12: val_loss did not improve from 0.67940\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 969ms/step - accuracy: 0.6639 - loss: 0.7707 - precision: 0.6639 - recall: 0.6639 - val_accuracy: 0.6578 - val_loss: 0.7078 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 1.5000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905ms/step - accuracy: 0.6656 - loss: 0.7679 - precision: 0.6656 - recall: 0.6656\n",
      "Epoch 13: val_loss did not improve from 0.67940\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 962ms/step - accuracy: 0.6655 - loss: 0.7679 - precision: 0.6655 - recall: 0.6655 - val_accuracy: 0.6578 - val_loss: 0.8214 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 1.5000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917ms/step - accuracy: 0.6531 - loss: 0.7761 - precision: 0.6531 - recall: 0.6531\n",
      "Epoch 14: val_loss improved from 0.67940 to 0.64413, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 975ms/step - accuracy: 0.6532 - loss: 0.7761 - precision: 0.6532 - recall: 0.6532 - val_accuracy: 0.6578 - val_loss: 0.6441 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 1.5000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914ms/step - accuracy: 0.6586 - loss: 0.7600 - precision: 0.6586 - recall: 0.6586\n",
      "Epoch 15: val_loss improved from 0.64413 to 0.62285, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 974ms/step - accuracy: 0.6586 - loss: 0.7600 - precision: 0.6586 - recall: 0.6586 - val_accuracy: 0.6578 - val_loss: 0.6228 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 1.5000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912ms/step - accuracy: 0.6599 - loss: 0.7532 - precision: 0.6599 - recall: 0.6599\n",
      "Epoch 16: val_loss did not improve from 0.62285\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 969ms/step - accuracy: 0.6599 - loss: 0.7532 - precision: 0.6599 - recall: 0.6599 - val_accuracy: 0.6578 - val_loss: 0.6529 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 1.5000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910ms/step - accuracy: 0.6585 - loss: 0.7511 - precision: 0.6585 - recall: 0.6585\n",
      "Epoch 17: val_loss improved from 0.62285 to 0.59888, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 967ms/step - accuracy: 0.6585 - loss: 0.7511 - precision: 0.6585 - recall: 0.6585 - val_accuracy: 0.6578 - val_loss: 0.5989 - val_precision: 0.6578 - val_recall: 0.6578 - learning_rate: 1.5000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922ms/step - accuracy: 0.6549 - loss: 0.7486 - precision: 0.7760 - recall: 0.4820\n",
      "Epoch 18: val_loss did not improve from 0.59888\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 982ms/step - accuracy: 0.6550 - loss: 0.7486 - precision: 0.7763 - recall: 0.4817 - val_accuracy: 0.6578 - val_loss: 0.6318 - val_precision: 0.9350 - val_recall: 0.6134 - learning_rate: 1.5000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941ms/step - accuracy: 0.6564 - loss: 0.7457 - precision: 0.9342 - recall: 0.3721\n",
      "Epoch 19: val_loss improved from 0.59888 to 0.56835, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 1s/step - accuracy: 0.6564 - loss: 0.7457 - precision: 0.9342 - recall: 0.3721 - val_accuracy: 0.6578 - val_loss: 0.5684 - val_precision: 0.9153 - val_recall: 0.6489 - learning_rate: 1.5000e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938ms/step - accuracy: 0.6595 - loss: 0.7338 - precision: 0.9384 - recall: 0.3784\n",
      "Epoch 20: val_loss did not improve from 0.56835\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 1s/step - accuracy: 0.6594 - loss: 0.7338 - precision: 0.9384 - recall: 0.3784 - val_accuracy: 0.6578 - val_loss: 0.6394 - val_precision: 0.9927 - val_recall: 0.5810 - learning_rate: 1.5000e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902ms/step - accuracy: 0.6547 - loss: 0.7424 - precision: 0.9491 - recall: 0.3638\n",
      "Epoch 21: val_loss did not improve from 0.56835\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 966ms/step - accuracy: 0.6547 - loss: 0.7423 - precision: 0.9491 - recall: 0.3638 - val_accuracy: 0.6578 - val_loss: 0.5704 - val_precision: 0.9428 - val_recall: 0.6389 - learning_rate: 1.5000e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903ms/step - accuracy: 0.6640 - loss: 0.7235 - precision: 0.9341 - recall: 0.3876\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.500000213738531e-05.\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.56835\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 967ms/step - accuracy: 0.6640 - loss: 0.7235 - precision: 0.9341 - recall: 0.3876 - val_accuracy: 0.6613 - val_loss: 0.5912 - val_precision: 0.9414 - val_recall: 0.6283 - learning_rate: 1.5000e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901ms/step - accuracy: 0.6751 - loss: 0.7166 - precision: 0.9253 - recall: 0.3852\n",
      "Epoch 23: val_loss improved from 0.56835 to 0.50514, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 965ms/step - accuracy: 0.6751 - loss: 0.7166 - precision: 0.9253 - recall: 0.3852 - val_accuracy: 0.7534 - val_loss: 0.5051 - val_precision: 0.9725 - val_recall: 0.6912 - learning_rate: 4.5000e-05\n",
      "Epoch 24/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923ms/step - accuracy: 0.7083 - loss: 0.6571 - precision: 0.9170 - recall: 0.4479\n",
      "Epoch 24: val_loss improved from 0.50514 to 0.46820, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 984ms/step - accuracy: 0.7083 - loss: 0.6571 - precision: 0.9170 - recall: 0.4480 - val_accuracy: 0.7846 - val_loss: 0.4682 - val_precision: 0.9830 - val_recall: 0.7175 - learning_rate: 4.5000e-05\n",
      "Epoch 25/25\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943ms/step - accuracy: 0.7294 - loss: 0.6194 - precision: 0.9167 - recall: 0.4739\n",
      "Epoch 25: val_loss improved from 0.46820 to 0.41385, saving model to best_stable_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 1s/step - accuracy: 0.7294 - loss: 0.6194 - precision: 0.9167 - recall: 0.4739 - val_accuracy: 0.7985 - val_loss: 0.4138 - val_precision: 0.9632 - val_recall: 0.7726 - learning_rate: 4.5000e-05\n",
      "Restoring model weights from the end of the best epoch: 25.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=val_generator,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bbdd3b",
   "metadata": {},
   "source": [
    "Worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8449d796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
